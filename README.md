# Big Data Flight Project  
**End-to-End Big Data Pipeline with Kafka, Spark, Airflow, SQL Server & Metabase**

---

## Project Overview

This project implements a **complete Big Data pipeline** for processing flight data, from raw CSV files to analytics dashboards.

The system is designed following **modern Data Engineering architecture**, including:
- Streaming ingestion with **Apache Kafka**
- Distributed processing with **Apache Spark**
- Workflow orchestration with **Apache Airflow**
- Data warehouse storage in **SQL Server**
- Visualization with **Metabase**

---

## System Architecture
CSV
â†“
Kafka (Batch Producer)
â†“
Spark Bronze Layer
â†“
Spark Silver Layer
â†“
Machine Learning Training (Spark MLlib)
â†“
SQL Server (Gold Layer)
â†“
Metabase Dashboard


---

## Technology Stack

| Layer | Technology |
|---|---|
| Ingestion | Apache Kafka |
| Processing | Apache Spark |
| Orchestration | Apache Airflow |
| Storage (Gold) | SQL Server |
| Visualization | Metabase |
| Containerization | Docker & Docker Compose |

---

## Project Structure

bigdata-flight-project/
â”œâ”€â”€ airflow/
â”‚ â””â”€â”€ dags/
â”‚ â””â”€â”€ flights_full_pipeline.py
â”œâ”€â”€ kafka/
â”‚ â””â”€â”€ producer_full_batch.py
â”œâ”€â”€ spark/
â”‚ â”œâ”€â”€ bronze_kafka_to_parquet_full.py
â”‚ â”œâ”€â”€ silver_full_etl.py
â”‚ â”œâ”€â”€ train_models.py
â”‚ â””â”€â”€ silver_to_sql.py
â”œâ”€â”€ jars/
â”‚ â””â”€â”€ mssql-jdbc-12.6.1.jre11.jar
â”œâ”€â”€ warehouse/
â”‚ â””â”€â”€ init.sql
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md


---

## ğŸ”„ Data Pipeline Explanation

### 1ï¸âƒ£ Data Ingestion (Kafka)
- Flight data is read from CSV files
- A Kafka batch producer sends data to a Kafka topic

**File:**  
`kafka/producer_full_batch.py`

---

### 2ï¸âƒ£ Bronze Layer (Spark)
- Spark consumes data from Kafka
- Raw data is stored in Parquet format (Bronze layer)

**File:**  
`spark/bronze_kafka_to_parquet_full.py`

---

### 3ï¸âƒ£ Silver Layer (Spark)
- Data cleaning and transformation
- Schema standardization and quality checks

**File:**  
`spark/silver_full_etl.py`

---

### 4ï¸âƒ£ Machine Learning Training
- Train ML models using Spark MLlib on Silver data
- Model training is part of the pipeline

**File:**  
`spark/train_models.py`

---

### 5ï¸âƒ£ Gold Layer â€“ Data Warehouse
- Cleaned data is loaded into SQL Server
- Optimized for analytics and BI queries

**File:**  
`spark/silver_to_sql.py`

---

### Visualization
- Metabase connects to SQL Server
- Dashboards visualize flight statistics and insights

---

## Workflow Orchestration with Airflow

Apache Airflow is used to **orchestrate the entire pipeline**, ensuring correct execution order and fault tolerance.

### Airflow DAG
**File:**  
`airflow/dags/flights_full_pipeline.py`

### DAG Flow
http://localhost:8080
Trigger the DAG: flights_full_pipeline

